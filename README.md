 ğŸ“¦ Data Pipeline for MySQL to Postgres + Kafka Integration with Debezium, Dagster, Metabase & Data Quality

This project implements a full data pipeline that:

- **Migrates data** from a **MySQL** source to **PostgreSQL** using **pgloader**
- **Streams changes** from MySQL to Kafka using **Debezium**
- **Visualizes** data in **Metabase**
- Orchestrates and **validates data quality** using **Dagster** and **Great Expectations**

---

## ï¿½ Architecture Overview
MySQL (source) â†’ pgloader â†’ PostgreSQL (target)
|
(Debezium CDC)
â†“
Kafka (broker)
â†“
Dagster (orchestration & DQ)
â†“
Metabase (BI & dashboarding)

text

## ğŸ³ Docker Services

| Service          | Description                                      |
|------------------|--------------------------------------------------|
| source-mysql     | MySQL 5.7 instance with initialized data         |
| target-postgres  | PostgreSQL 15 for storing migrated data          |
| pgloader         | One-time migration from MySQL to PostgreSQL      |
| zookeeper        | Zookeeper instance required for Kafka            |
| kafka            | Apache Kafka message broker                      |
| debezium         | Debezium CDC connector for MySQL to Kafka        |
| metabase         | Visualization and BI dashboard                   |

## ğŸ“ Project Structure
.
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ 1_mysql_initialization/
â”‚ â””â”€â”€ sql/ # Initial SQL scripts for MySQL
â”œâ”€â”€ 2_postgres_migration/
â”‚ â”œâ”€â”€ pgloader-config/
â”‚ â”‚ â””â”€â”€ migration.load # pgloader configuration
â”‚ â””â”€â”€ debezium-config/
â”‚ â””â”€â”€ mysql-connector.json # Debezium config
â””â”€â”€ data_pipeline/
â”œâ”€â”€ data_pipeline/ # Dagster project (C:\Users\HA\Desktop\stage-gda-real\uatrs-data-pipeline\data_pipeline\data_pipeline)
â””â”€â”€ dbt/ # dbt project

text

## ğŸ› ï¸ Requirements

### Python (for Dagster in data_pipeline/data_pipeline/)
```bash
pip install great-expectations==0.15.50 pandas==1.5.3 numpy==1.23.5 SQLAlchemy==1.4.5
pip install dagster==1.11.2 dagster-webserver==1.11.2 dagster-graphql==1.11.2 \
            dagster-dbt==0.27.2 dagster-postgres==0.27.2 dagster-ge==0.27.2
ğŸš€ Getting Started
Clone the repository:

bash
git clone <repo-url>
cd <repo-folder>
Start the stack:

bash
docker-compose up --build
âš ï¸ Ensure ports 3307, 5433, 29092, 8083, and 3001 are available.

Access services:

Metabase: http://localhost:3001

Dagster: http://localhost:3000 (after starting with dagster dev)

ğŸ” Database Credentials
Component	Host	Port	DB Name	User	Password
MySQL	localhost	3307	uatrs_db	uatrs_user	uatrs_pass
PostgreSQL	localhost	5433	uatrs_db	uatrs_user	uatrs_pass
ğŸ§ª Running Data Quality Checks
Navigate to Dagster project:

bash
cd data_pipeline/data_pipeline/
Start Dagster:

bash
dagster dev
Access UI at http://localhost:3000 to:

Run pipelines

Validate data with Great Expectations

Monitor data quality

ğŸ“Š Metabase Setup
Access http://localhost:3001

Connect to PostgreSQL using credentials above

Create dashboards and visualizations

ğŸ“Œ Notes
Debezium config: ./2_postgres_migration/debezium-config/mysql-connector.json

MySQL init scripts: ./1_mysql_initialization/sql/

Data persists in Docker volumes:

mysql_data

postgres_data
