# ğŸ“¦ Data Pipeline: MySQL to PostgreSQL + Kafka + Dagster + DBT + Metabase

Ce projet met en place un pipeline de donnÃ©es complet qui :

- ğŸ”„ **Migre les donnÃ©es** de **MySQL** vers **PostgreSQL** (via `pgloader`)  
- ğŸ” **Capture les changements** avec **Debezium** et les transmet Ã  **Kafka**  
- âš™ï¸ **Orchestre** les traitements avec **Dagster**  
- ğŸ› ï¸ **Transforme** les donnÃ©es dans PostgreSQL avec **DBT**  
- ğŸ“Š **Analyse et visualise** les donnÃ©es dans **Metabase**

---

## ğŸ“š Table des matiÃ¨res

1. [Architecture du Pipeline](#-architecture-overview)  
2. [Installation et Configuration de la Partie Extraction](#-extraction-migration)  
3. [Installation et Configuration de DBT](#-dbt-installation-et-configuration)  
4. [IntÃ©gration Dagster](#-dagster-integration)  
5. [Installation et Configuration de Metabase](#-metabase-installation-et-configuration)  
6. [DÃ©marrage du Pipeline](#-demarrage-du-pipeline)  

---

## ğŸ—ºï¸ Architecture du Pipeline

Voici lâ€™architecture globale de la solution :
![Diagramme dâ€™architecture](pipeline_de_donnÃ©es.png)


```text
MySQL (source) 
  â”‚
  â”œâ”€â”€â–¶ pgloader (migration initiale)
  â”‚
  â””â”€â”€â–¶ Debezium â†’ Kafka (CDC)
                          â”‚
                          â””â”€â”€â–¶ Dagster (orchestration)
                                    â”‚
                                    â”œâ”€â”€â–¶ DBT (transformations SQL dans PostgreSQL)
                                    â”‚
                                    â””â”€â”€â–¶ PostgreSQL (donnÃ©es transformÃ©es)
                                                â”‚
                                                â””â”€â”€â–¶ Metabase (visualisation)

Pipeline ELT : Extract, Load, Transform
Extraction : les donnÃ©es sont extraites de MySQL (source).

Chargement : les donnÃ©es brutes sont chargÃ©es dans PostgreSQL, via pgloader (migration initiale) ou via Debezium + Kafka (CDC en temps rÃ©el).

Transformation : DBT transforme et modÃ©lise les donnÃ©es dans PostgreSQL, prÃ©parant les tables pour lâ€™analyse.

Visualisation : Metabase permet de crÃ©er des dashboards basÃ©s sur les donnÃ©es transformÃ©es.

Lâ€™orchestration globale est gÃ©rÃ©e par Dagster qui lance les Ã©tapes DBT, contrÃ´le la qualitÃ© des donnÃ©es, etc.
ğŸ”§ Extraction & Migration (pgloader, Debezium, Kafka)
ğŸ³ Docker Services
Service	Description
source-mysql	MySQL 5.7 instance with initialized data
target-postgres	PostgreSQL 15 for storing migrated data
pgloader	One-time migration from MySQL to PostgreSQL
zookeeper	Zookeeper instance required for Kafka
kafka	Apache Kafka message broker
debezium	Debezium CDC connector for MySQL to Kafka
metabase	Visualization and BI dashboard
ğŸ› ï¸ PrÃ©requis
Python (pour Dagster dans data_pipeline/data_pipeline/):

bash
Copier
Modifier
pip install great-expectations==0.15.50 pandas==1.5.3 numpy==1.23.5 SQLAlchemy==1.4.5
pip install dagster==1.11.2 dagster-webserver==1.11.2 dagster-graphql==1.11.2 \
            dagster-dbt==0.27.2 dagster-postgres==0.27.2 dagster-ge==0.27.2
ğŸš€ DÃ©marrage - Extraction & Migration
Cloner le dÃ©pÃ´t

bash
Copier
Modifier
git clone <repo-url>
cd <repo-folder>
Lancer la stack Docker

bash
Copier
Modifier
docker-compose up --build
âš ï¸ Assurez-vous que les ports 3307, 5433, 29092, 8083 et 3001 sont libres.

AccÃ¨s aux services

Metabase: http://localhost:3001

Dagster: http://localhost:3000 (aprÃ¨s dÃ©marrage avec dagster dev)

Identifiants des bases

Composant	Host	Port	DB Name	User	Password
MySQL	localhost	3307	uatrs_db	uatrs_user	uatrs_pass
PostgreSQL	localhost	5433	uatrs_db	uatrs_user	uatrs_pass

ğŸ› ï¸ DBT Installation et Configuration
CrÃ©er un environnement virtuel et activer

bash
Copier
Modifier
python -m venv dbt_venv
# Sur Windows PowerShell
.\dbt_venv\Scripts\Activate.ps1
# Sur Linux/Mac
source dbt_venv/bin/activate
Installer DBT

bash
Copier
Modifier
pip install dbt-core dbt-postgres
Cloner le projet DBT (ou utiliser le dossier existant)

bash
Copier
Modifier
git clone https://github.com/Idriss-Abidi/DataWarehouse_BI
Configurer le fichier profiles.yml

Exemple :

yaml
Copier
Modifier
dbt_proj:
  outputs:
    dev:
      type: "postgres"
      host: "localhost"
      user: "your_user"
      password: "your_password"
      port: 5432
      dbname: "ourDatabase"
      schema: "public"
      threads: 1
  target: "dev"
Tester la connexion

bash
Copier
Modifier
dbt debug
Lancer les transformations

bash
Copier
Modifier
dbt run
âš™ï¸ Dagster Integration
Installer Dagster et plugins DBT

bash
Copier
Modifier
pip install dagster dagster-dbt dagster-webserver
Scaffold un projet Dagster DBT

bash
Copier
Modifier
dagster-dbt project scaffold --project-name my_dagster_project --dbt-project-dir <path_to_dbt_project>
Lancer Dagster

bash
Copier
Modifier
cd my_dagster_project
dagster dev -p 5000
Interface accessible sur http://localhost:5000

ğŸ“Š Metabase Installation et Configuration
Installer Metabase avec Docker

bash
Copier
Modifier
docker pull metabase/metabase
docker run -d --name metabase -p 3000:3000 <path_to_dashboard_folder>:/metabase.db metabase/metabase
AccÃ©der Ã  Metabase

http://localhost:3000

Configurer la connexion Ã  PostgreSQL

Database Name: <database_name>

Host: host.docker.internal

Port: 5432

Username: postgres (ou celui configurÃ©)

Password: <votre_mot_de_passe>

CrÃ©er vos dashboards

ğŸ DÃ©marrage complet du pipeline
docker-compose up --build pour lancer les services

dagster dev -p 5000 pour Dagster

AccÃ©der aux dashboards Metabase

Lancer les pipelines et transformations via Dagster

T


