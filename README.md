ğŸ“¦ Data Pipeline for MySQL to Postgres + Kafka Integration with Debezium, Dagster, Metabase & Data Quality


Ce projet met en place un pipeline de donnÃ©es complet qui :

- ğŸ”„ **Migre les donnÃ©es** de **MySQL** vers **PostgreSQL** (via `pgloader`)  
- ğŸ” **Capture les changements** avec **Debezium** et les transmet Ã  **Kafka**  
- âš™ï¸ **Orchestre** les traitements avec **Dagster**  
- ğŸ› ï¸ **Transforme** les donnÃ©es dans PostgreSQL avec **DBT**  
- ğŸ“Š **Analyse et visualise** les donnÃ©es dans **Metabase**

---

## ğŸ“š Table des matiÃ¨res

1. [Architecture du Pipeline](#-architecture-overview)  
2. [Installation et Configuration de la Partie Extraction](#-extraction-migration)  
3. [Installation et Configuration de DBT](#-dbt-installation-et-configuration)  
4. [IntÃ©gration Dagster](#-dagster-integration)  
5. [Installation et Configuration de Metabase](#-metabase-installation-et-configuration)  
6. [DÃ©marrage du Pipeline](#-demarrage-du-pipeline)  

---

## ğŸ—ºï¸ Architecture du Pipeline

Voici lâ€™architecture globale de la solution :
![Diagramme dâ€™architecture](pipeline_de_donnÃ©es.png)


```text
MySQL (source) 
  â”‚
  â”œâ”€â”€â–¶ pgloader (migration initiale)
  â”‚
  â””â”€â”€â–¶ Debezium â†’ Kafka (CDC)
                          â”‚
                          â””â”€â”€â–¶ Dagster (orchestration)
                                    â”‚
                                    â”œâ”€â”€â–¶ DBT (transformations SQL dans PostgreSQL)
                                    â”‚
                                    â””â”€â”€â–¶ PostgreSQL (donnÃ©es transformÃ©es)
                                                â”‚
                                                â””â”€â”€â–¶ Metabase (visualisation)

Pipeline ELT : Extract, Load, Transform
Extraction : les donnÃ©es sont extraites de MySQL (source).

Chargement : les donnÃ©es brutes sont chargÃ©es dans PostgreSQL, via pgloader (migration initiale) ou via Debezium + Kafka (CDC en temps rÃ©el).

Transformation : DBT transforme et modÃ©lise les donnÃ©es dans PostgreSQL, prÃ©parant les tables pour lâ€™analyse.

Visualisation : Metabase permet de crÃ©er des dashboards basÃ©s sur les donnÃ©es transformÃ©es.

Lâ€™orchestration globale est gÃ©rÃ©e par Dagster qui lance les Ã©tapes DBT, contrÃ´le la qualitÃ© des donnÃ©es, etc.
ğŸ”§ Extraction & Migration (pgloader, Debezium, Kafka)
## ğŸ³ Docker Services

| Service          | Description                                      |
|------------------|--------------------------------------------------|
| source-mysql     | MySQL 5.7 instance with initialized data         |
| target-postgres  | PostgreSQL 15 for storing migrated data          |
| pgloader         | One-time migration from MySQL to PostgreSQL      |
| zookeeper        | Zookeeper instance required for Kafka            |
| kafka            | Apache Kafka message broker                      |
| debezium         | Debezium CDC connector for MySQL to Kafka        |
| metabase         | Visualization and BI dashboard    

## ğŸ› ï¸ Requirements
1. Installation Python / Dagster

pip install  pandas==1.5.3 numpy==1.23.5 SQLAlchemy==1.4.5
pip install dagster==1.11.2 dagster-webserver==1.11.2 dagster-graphql==1.11.2 \
            dagster-dbt==0.27.2 dagster-postgres==0.27.2 dagster-ge==0.27.2

ğŸš€ Getting Started
Clone the repository:

bash
git clone <repo-url>
cd <repo-folder>
Start the stack:

bash
docker-compose up --build

Metabase: http://localhost:3001

Dagster: http://localhost:3000 (aprÃ¨s dÃ©marrage avec dagster dev)

Identifiants des bases

Composant  	Host	      Port	   DB  Name	   User	       Password
MySQL	      localhost	  3307	   uatrs_db	   uatrs_user	 uatrs_pass
PostgreSQL	localhost 	5433	   uatrs_db	   uatrs_user  uatrs_pass



ğŸ› ï¸ DBT Installation et Configuration
CrÃ©er un environnement virtuel et activer

python -m venv dbt_venv
# Sur Windows PowerShell
.\dbt_venv\Scripts\Activate.ps1
# Sur Linux/Mac
source dbt_venv/bin/activate
Installer DBT

pip install dbt-core dbt-postgres
Cloner le projet DBT (ou utiliser le dossier existant)

git clone https://github.com/Idriss-Abidi/DataWarehouse_BI
Configurer le fichier profiles.yml

Exemple :

yaml
dbt_proj:
  outputs:
    dev:
      type: "postgres"
      host: "localhost"
      user: "your_user"
      password: "your_password"
      port: 5432
      dbname: "ourDatabase"
      schema: "public"
      threads: 1
  target: "dev"
Tester la connexion

dbt debug
Lancer les transformations

dbt deps
installer les dependances

dbt run
pour excÃ©uter vos models

dbt docs generate
dbt docs serve
dans le but de voir DAG de vos models pour en pouvoir visualiser les dÃ©pendances
 
ğŸ› ï¸ DÃ©tails sur l'exÃ©cution de DBT avec variables dâ€™environnement

Avant de lancer les commandes DBT, il est nÃ©cessaire dâ€™exÃ©cuter un script envbat (ou tout autre script dâ€™environnement) qui permet de charger les variables dâ€™environnement nÃ©cessaires au fonctionnement global du pipeline.

Pourquoi exÃ©cuter envbat ?
Ce script dÃ©finit des variables dâ€™environnement (par exemple des chemins, des clÃ©s API, des paramÃ¨tres de connexion...) indispensables au bon fonctionnement des Ã©tapes suivantes.

Sans ces variables, certains scripts, notamment le script Python de gÃ©nÃ©ration de fichiers SQL, risquent de ne pas fonctionner correctement.

Processus complet
Lancer le script env.bat
call env.bat
Cela charge toutes les variables dâ€™environnement dans la session actuelle.

ExÃ©cuter le script Python de gÃ©nÃ©ration des fichiers SQL 
Ce script crÃ©e automatiquement plusieurs fichiers .sql, un par ID disponible (exemple : un fichier par client, projet ou autre identifiant mÃ©tier).
Ces fichiers SQL font appel Ã  des macros DBT rÃ©utilisables, permettant de standardiser et simplifier les transformations.

Se positionner dans le dossier DBT
cd <chemin_du_dossier_dbt>
Lancer DBT pour compiler et exÃ©cuter les modÃ¨les

âš™ï¸ Dagster Integration
Installer Dagster et plugins DBT
pip install dagster dagster-dbt dagster-webserver

Scaffold un projet Dagster DBT
dagster-dbt project scaffold --project-name my_dagster_project --dbt-project-dir <path_to_dbt_project>

Lancer Dagster
cd my_dagster_project
dagster dev -p 4000

Interface accessible sur http://localhost:4000
ğŸ“Š Metabase Installation et Configuration
Installer Metabase avec Docker
docker pull metabase/metabase
docker run -d --name metabase -p 3000:3000 <path_to_dashboard_folder>:/metabase.db metabase/metabase

AccÃ©der Ã  Metabase
http://localhost:3000
Configurer la connexion Ã  PostgreSQL
Database Name: <database_name>
Host: host.docker.internal
Port: 5432
Username: postgres (ou celui configurÃ©)
Password: <votre_mot_de_passe>

CrÃ©er vos dashboards
ğŸ DÃ©marrage complet du pipeline
docker-compose up --build pour lancer les services

dagster dev -p 4000 pour Dagster

AccÃ©der aux dashboards Metabase

Lancer les pipelines et transformations via Dagster
